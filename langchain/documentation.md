# LangChain中文手册

## 介绍

LangChain是一个开发由语言模型驱动的应用程序的框架。我们相信，最强大和差异化的应用程序不仅会通过API调用语言模型，还能做到以下两点：

1. 数据感知：将语言模型连接到其他数据源
2. 代理：允许语言模型与其环境进行交互

因此，LangChain框架的设计目标是支持这些类型的应用程序。

LangChain框架提供了两个主要部分：

1. 组件集合
   LangChain为使用语言模型所需组件提供了模块化抽象。LangChain还提供了所有这些抽象的具体实现。   这些组件精心设计，易于使用，无论是否使用LangChain框架的其余部分，都可使用这些组件。

2. 用例链集合
   链（Chain）是为了完成特定工作，将上面的组件组装起来的一种方式。这是一个高层接口，通过这些接口可以很容易的完成特定工作。这些链设计时也考虑的可定制化。

因此，我们将后续文档分为这两大部分。

## 组件集合
本节首先讲述底层schema抽象，然后深入探讨LangChain的六种主要组件

* [Schema抽象](#schema抽象) ，共4项
* [模型](#模型)，共3项
* [提示语](#提示语)，共4项
* [索引](#索引)，共4项
* [记忆](#记忆)，共1项
* [链](#链)，共4项
* [代理](#代理)，共4项

### Schema抽象
本节讲述文档中使用的主要四种类型和schema

1. 文本(Text)

使用语言模型时，与其交互的主要接口就是文本。简言之，很多模型就是输入文本，输出文本。所以大量LangChain的接口都围绕文本展开。

2. 聊天消息(ChatMessage)

终端用户使用的主要界面是聊天界面。因此，一些模型提供商甚至开始以聊天消息的方式提供对底层API的访问。这些消息具有内容字段（通常为文本），与用户关联。目前支持的用户包括系统，人类和AI。

* 系统聊天消息(SystemChatMessage)

代表作为AI系统指令的聊天消息

* 人类聊天消息(HumanChatMessage)

来自于AI系统交互的人类聊天消息

* AI聊天消息(AIChatMessage)

来自AI系统的聊天消息

3. 示例(Example)

实例是输入/输出对，表示对一个函数的输入，以及期望的输出。可用于训练和评估模型。

输入/输出对可以是面向模型的，也可以是面向链的。这两类有不同的用户。面向模型的示例可用于微调模型，面向链的示例可用于评估端到端的链，甚至可以训练模型来替换整个链。

4. 文档(Document)

文档是一段非结构化数据。由`page_content`(数据内容)和`metadata`(描述数据属性的信息)组成。

### 模型(Model)

本节涉及LangChain使用的不同类型的模型。主要有如下三类：

* 大语言模型

大语言模型(LLM)将文本作为输入，返回文本作为输出。

* 聊天模型

聊天模型通常由语言模型支持，但其API更结构化，具体而言，这些模型将聊天消息列表作为输入，返回一个聊天消息。

* 文本嵌入模型

这类模型对文本进行向量化，将文本作为输入，返回其对应的一列浮点数。

### 提示语(Prompt)

模型编程的新方式是使用提示语。一个“提示语”指的是对模型的输入，这个输入很少手工直接编写，通常由多个组件构建。提示语模板（PromptTemplate）负责这个输入的构建。LangChain提供多个类和函数，用以简化提示语的构建和使用。

* 提示语的值(PromptValue)

这个类代表了模型的输入，指的是向底层模型传入的内容。现在提示语主要是文本数据，其他类型的数据（图片，音频）正在添加，但目前尚未实现。

不同模型需要不同数据格式，可能情况下，我们希望在不同的模型中使用相同的提示。因此，我们有了提示语的值（PromptValue）的概念。这个类有方法转为每种模型需要的具体输入，目前主要是文本或聊天消息。

* 提示语模板（Prompt Template）

这个类用于构建提示语的值（PromptValue），提示语的值是最终传给模型的内容，大多数情况下这个值不是手工编写，而是基于用户输入及其他来自多个来源的非静态信息使用提示语模板动态创建。

* 示例选择器（Example Selector）

经常在提示语中包含示例非常有用。这些示例可以手工编写，但动态选择时更加灵活强大。ExampleSelector是将用户输入转化为一组示例的对象。

* 输出解析器（OutputParser）

语言模型（以及聊天模型）输出文本。但是通常你会需要获取更加结构化的信息，这时就用到输出解析器了。输出解析器负责：1. 只是模型输出如何格式化；2. 将输出解析为期望的格式（必要时重试）。输出解析器必须实现如下两个主要方法：
1. `get_format_instructions() -> str`: 返回包含语言模型如何格式化输出的指令的字符串
2. `parse(str) -> Any`: 获取一个文本（通常为语言模型的响应），将其解析为某种格式

还可实现如下可选方法：
1. `parse_with_prompt(str) -> Any`: 根据一个文本（语言模型的响应）和一个提示语（生成这个响应的提示语），将文本解析为某种结构。OutputParser有可能使用这个提示语重试。

### 索引(Index)

索引指的是构建文档的方法，以便LLM更好与其交互。本模块包含了工具函数，用来处理文档、不同类型的索引，以及链中使用这些索引的示例。

在链中使用索引的最常用方式是在检索步骤中使用。这个步骤指的是使用用户的输入，返回最相关的文档。之所以做这个区分，因为（1）索引可用于检索之外的其他事情（2）检索可使用索引之外的其他逻辑找到相关文档。所以我们有一个Retriever接口，大多数Chain都会使用。

大多数情况下，我们讨论索引(Index)和检索（retrieval）时，我们说的是索引和检索非结构化数据（如文本文档）。对于与结构化数据（SQL表等）或API的交互，请看相关用例。LangChain支持的主要索引和检索类型集中在向量数据库上。

* 文档加载器（Document Loader）

加载一列文档对象。

* 文本分割器（Text Splitter）

通常大语言模型对输入文本的长度有限制。为了更好地使用大语言模型，我们需要将大的文本文档分割为小块。TextSplitter就是做这事儿的。

* 向量存储（Vector Store）

向量存储是使用一个嵌入模型（Embedding Model）将文档转化为向量（称为vector embedding）并将向量和对应文档存储起来的系统。向量存储可以通过向量（vector embedding）快速检索相关文档。

* 取回器（Retriever）

一种存储数据的方式，以便语言模型可以查询。这个接口暴露的唯一方法是`get_relevant_texts`，拿着一个字符串作为输入，返回一列文档。

### 记忆（Memory) 

记忆是会话过程中存储和检索数据的概念，主要有两个方法：
1. 基于输入，获取相关数据
2. 基于输入和输出，更细状态。

主要由两类记忆：短期记忆和长期记忆。

短期记忆指的是如何将数据作为单个会话的上下文传过去（通常是前面的ChatMessage或他们的总结）。

长期记忆处理如何在会话间提取或更新信息。

当前语言模型的主要界面是聊天界面，ChatMessageHistory类用来记住同一会话前面的所有聊天。这些可以直接传给模型，或用某种方式总结后传给模型，或者采用某种组合方式传给模型。

ChatMessageHistory提供了两个方法和一个属性：
* `add_user_message`：存储用户输入
* `add_ai_message`：存储AI的输出
* `messages`：返回所有前述消息。

### 链(Chain)

链只是对多个单独组件的端到端封装。

#### `LLMChain`
大语言链是最常用的链类型，包括了一个提示语模板，一个模型（LLM或聊天模型），或一个可选的输出解析器。LLMChain拿到多个输入变量，使用提示语模板将其格式化为输入，接着将输入传给模型，最后使用输出解析器（如果有的话）将模型输出解析为最终格式。

#### `Index-related chain`
索引相关链用于与索引交互。这些链的目的是将你自己的数据（存储在index中）与LLM结合。最好的例子就是基于你自己文档的问答。

这些链很大一部分是理解如何将多个文档传给语言模型。有不同的方法和链完成这些事。LangChain支持其中四种最通用的方法，按照从简单到复杂划分如下：

1. Stuffing（填料）
这是最简单的方法，只需将所有相关数据放到提示语中，作为上下文传给语言模型即可。在LangChain中，由StuffDocumentsChain实现。这种方法的好处是只需调用LLM一次即可。当生成文本时，LLM能访问所有数据。坏处是绝大多数LLM有一个上下文长度上线，对于大文档或多个文档来说，这种方法不适用，因为会导致提示语超过上下文长度。所以这种方法只在少量数据时适用。

2. MapReduce（映射归纳法）
这种方法牵扯到对于每一块数据执行一次提示语（对于总结任务，这可以是对每一块的总结；对问答任务，这可以是基于每一块儿的回答），然后一个新的提示语用来合并所有这些输出。LangChain通过MapReduceDocumentsChain来实现这种方法。这种方法的好处是可以扩展到大文档或更多文档中，基于多个文档对LLM的调用是独立的，所以可以并行；坏处是需要调用LLM多次，在最后的合并调用中会丢失一些信息。

3. Refine（完善法）
这种方法对第一块数据执行提示语，获取输出后将输出与第二个文档一起，让LLM基于此完善输出。此方法好处是可以获得更多上下文，比MapReduceDocumentsChain损失更少内容，坏处是需要调用多次LLM，另外这些调用不是独立的，不能并发。

4. Map-Rerank（映射重排名法）

#### Prompt Selector

LangChain中，chain的一个目标，就是让人尽快启动一个特定用例，而这其中很大的一块儿就是有好的提示语。

问题是对一个模型工作的提示语，在其他模型上不一定工作。我们希望chain可在所有模型上工作。所以，与手写提示语相反，我们有PromptSelector的概念，根据模型选择一个提示语。

最常用的用例，就是根据LLM和ChatModel设置不同的默认提示语。

### 代理

一些应用不仅需要一个预先确定的调用LLM和其他工具的chain，还需要未知的以来用户输入的chain。在这种chain中，有一个代理，可访问一系列工具。根据用户的输入，这个代理可以决定使用哪个工具。

#### 工具（Tool） 

语言模型如何与其他资源交互

工具的接口是一个文本输入和一个文本输出。

#### 代理（Agent)

语言模型驱动决策

代理是模型的封装，接收用户输入，根据一个动作返回一个响应。

#### 工具集（Toolkit）

一起完成特定任务的工具集

#### 代理执行器（AgentExecutor）

使用工具执行代理的逻辑。

代理执行器包括一个代理和一个工具集，负责调用代理，获取响应，调用工具，获取工具输出，将所有这些信息返回给agent，获取下个动作


## 使用案例集合

讲解LangChain实现的不同的端到端用例。

### 个人助理（Personal Assistants）

个人助理是完美使用LangChain构建的应用，因为它组合了LangChain主要的功能（动作执行和个性化数据）。为了构建个人助理，需要理解如下概念：

1. PromptTemplate
2. Memory
3. Tool
4. Agent
5. AgentExecutor

### 基于本地文档的问答（Question Answering Over Docs）

虽然LLM很强大，但他们不懂他们没有训练过的信息。如果你想让他们回答关于他们没有训练过的信息的问题，你需要给他们这些信息的内容。最常用的方法是通过“检索增强生成”。

检索增强生成的想法是，当给定一个问题时，你先执行一个检索步骤，获取任何相关的文档。然后将这些文档和原始问题传给语言模型，让它生成一个响应。但为了做到这一点，你需要将你的文档转化为可用这种方式查询的一种格式。本节描述这两个步骤：

#### 1. 将文档变为个查询格式；

为了使用语言模型与你的数据交互，首先将你的数据转化为合适的格式，这个格式应该是一种Index。通过将数据放到Index，将方便任何后续步骤与其交互。

有几种类型的Index，但目前为止最常用的是向量存储（VectorStore）。将数据转化为向量存储，可通过如下步骤完成：

1. 使用DocumentLoader加载文档
2. 使用TextSplitter分割文档
3. 使用一个TextEmbeddingModel为该文档生成向量嵌入（vector embeddings）
4. 将文档和嵌入出入到向量存储。

#### 2. 检索增强生成链。

现在已经有了索引，怎么用其生成响应？可将其分解为如下步骤：

1. 获取用户问题
2. 在索引中查询与其相关的文档
3. 根据问题和相关文档，使用PromptTemplate构造一个PromptValue
4. 将PromptValue传给模型
5. 获取结果，将其返回给用户。

### 对话机器人（Chatbot）

ChatGPT通过试用新界面-聊天-公布一个强大的语言模型而风靡世界。有几个组件用来构建聊天机器人：

1. 模型：可通过正常的语言模型或聊天模型构建chatbot。重要的是，即使使用聊天模型，API本身也是无状态的，意味着聊天模型不会记住前面的对话，你需要将前面对话和问题一起传给它。

2. 提示语模板：这将指导你的对话机器人如何工作。他们时髦吗？有用吗？这可以给你的对话机器人一些个性。
3. 记忆：如上所述，模型没有状态，记忆带来一些状态，允许它记住以前的交互。

对话机器人非常强大，在于其他数据源结合使用时更具特色。上一节基于文档问答的技术可同样用于这里，让你的对话机器人访问哪些个人数据。

### 查询表数据（Querying Tabular Data）

大量数据和信息保存在表结构中，他们通常是csv，excel，sql table。LangChain可以与这些数据进行交互。

可以将这些表结构的数据通过DocumentLoader加载到Index中，与文本数据和非结构化数据类似。然后使用类似的方式查询。

如果数据量很大，不想或不能加载到Index中，可以使用语言模型直接与其交互。

### 与API交互

API非常强大，可用来执行动作，也可用来查询数据。

### 数据抽取

语言模型非常善于从非结构化文本中抽取结构化信息。这非常有价值，因为大量信息以文本的方式存储，为了让这些信息更加有用，可以将这些信息转化为结构化格式。

这里最有用的概念就是OutputParser。OutputParser负责指定语言模型响应内容的格式，然后将原始文本输出解析为结构化格式。

### 评估（Evaluation）

评估一个链/代理是一个困难的问题，缺少数据，缺少指标。这也是一个正在解决中的问题。

### 总结（Summarization）

总结长文档是一个常见用例。这很容易达到上下文窗口长度限制。与问答问题不同，你不能做一些语义搜索，然后只选择与问题最相关的文本，因为在总结长文档场景中，没有特定的问题，你需要总结所有内容。

最常用的做法是将文档分割为多个小块，然后递归方式进行总结：首先对每个小块进行总结，然后将小块的总结进行合并，合并成更少的小块后再进行总结，直到最后只有一个小块。
